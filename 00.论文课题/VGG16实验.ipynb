{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'F:\\DataSets/EmotionImages/TargetData'\n",
    "\n",
    "data_transform = {x: transforms.Compose([transforms.Resize([224, 224]),  # 设置尺寸\n",
    "                                        transforms.ToTensor(),  # 转为Tensor\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])  # 标准化\n",
    "                  for x in {\"train\", \"valid\"}}  # {\"train\":\"训练集数据格式\",\"valid\":\"测试集数据格式\"}\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(root=os.path.join(data_dir, x),  # 载入数据\n",
    "                                         transform = data_transform[x])\n",
    "                  for x in {\"train\", \"valid\"}}  # {\"train\":\"训练集\",\"valid\":\"测试集\"}\n",
    "\n",
    "dataloader = {x: torch.utils.data.DataLoader(dataset=image_datasets[x],\n",
    "                                            batch_size=16,\n",
    "                                            shuffle=True)\n",
    "              for x in {\"train\", \"valid\"}}  # {包装16个为一个批次\"train\":\"训练集数据载入\",\"valid\":\"测试集数据载入\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader[\"train\"]))\n",
    "print(len(dataloader[\"valid\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X_example, y_example = next(iter(dataloader[\"train\"]))  # 迭代得到一个批次的样本\n",
    "example_classes = image_datasets[\"train\"].classes\n",
    "index_classes = image_datasets[\"train\"].class_to_idx\n",
    "print(len(example_classes))\n",
    "print((len(index_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\WZQAdmin/.cache\\torch\\checkpoints\\vgg16-397923af.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 528M/528M [01:05<00:00, 8.45MB/s]\n"
     ]
    }
   ],
   "source": [
    "# model = models.vgg16(pretrained=True)  # 使用VGG16 网络预训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('F:\\DataSets/VGG16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for parma in model.parameters():  # 设置自动梯度为false\n",
    "    parma.requires_grad = False\n",
    "\n",
    "model.classifier = torch.nn.Sequential(  # 修改全连接层 自动梯度会恢复为默认值\n",
    "    torch.nn.Linear(25088, 4096),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Linear(4096, 4096),\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Linear(4096, 3))\n",
    "Use_gpu = torch.cuda.is_available()\n",
    "if Use_gpu:  # 判断是否有cuda\n",
    "    model = model.cuda()\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss()  # 设置残差损失\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.00001)  # 使用Adam优化函数\n",
    "\n",
    "epoch_n = 5\n",
    "time_open = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch0/4\n",
      "----------\n",
      "Training...\n",
      "Batch10,TrainLoss:0.8860,Train ACC:65.0000\n",
      "Batch20,TrainLoss:0.8407,Train ACC:67.0000\n",
      "Batch30,TrainLoss:0.8023,Train ACC:71.0000\n",
      "Batch40,TrainLoss:0.7828,Train ACC:72.0000\n",
      "Batch50,TrainLoss:0.7583,Train ACC:73.0000\n",
      "Batch60,TrainLoss:0.7255,Train ACC:74.0000\n",
      "Batch70,TrainLoss:0.7096,Train ACC:75.0000\n",
      "Batch80,TrainLoss:0.6872,Train ACC:76.0000\n",
      "Batch90,TrainLoss:0.6715,Train ACC:76.0000\n",
      "Batch100,TrainLoss:0.6643,Train ACC:76.0000\n",
      "Batch110,TrainLoss:0.6518,Train ACC:76.0000\n",
      "train Loss:0.6437 Acc:77.000000%\n",
      "Validing...\n",
      "valid Loss:0.5886 Acc:73.000000%\n",
      "Epoch1/4\n",
      "----------\n",
      "Training...\n",
      "Batch10,TrainLoss:0.4136,Train ACC:83.0000\n",
      "Batch20,TrainLoss:0.3924,Train ACC:85.0000\n",
      "Batch30,TrainLoss:0.3772,Train ACC:87.0000\n",
      "Batch40,TrainLoss:0.3673,Train ACC:88.0000\n",
      "Batch50,TrainLoss:0.3653,Train ACC:88.0000\n",
      "Batch60,TrainLoss:0.3617,Train ACC:87.0000\n",
      "Batch70,TrainLoss:0.3657,Train ACC:87.0000\n",
      "Batch80,TrainLoss:0.3578,Train ACC:88.0000\n",
      "Batch90,TrainLoss:0.3510,Train ACC:88.0000\n",
      "Batch100,TrainLoss:0.3469,Train ACC:88.0000\n",
      "Batch110,TrainLoss:0.3419,Train ACC:89.0000\n",
      "train Loss:0.3382 Acc:89.000000%\n",
      "Validing...\n",
      "valid Loss:0.4899 Acc:80.000000%\n",
      "Epoch2/4\n",
      "----------\n",
      "Training...\n",
      "Batch10,TrainLoss:0.2039,Train ACC:93.0000\n",
      "Batch20,TrainLoss:0.1898,Train ACC:95.0000\n",
      "Batch30,TrainLoss:0.1876,Train ACC:96.0000\n",
      "Batch40,TrainLoss:0.1782,Train ACC:96.0000\n",
      "Batch50,TrainLoss:0.1805,Train ACC:96.0000\n",
      "Batch60,TrainLoss:0.1828,Train ACC:96.0000\n",
      "Batch70,TrainLoss:0.1822,Train ACC:96.0000\n",
      "Batch80,TrainLoss:0.1813,Train ACC:96.0000\n",
      "Batch90,TrainLoss:0.1785,Train ACC:95.0000\n",
      "Batch100,TrainLoss:0.1793,Train ACC:95.0000\n",
      "Batch110,TrainLoss:0.1786,Train ACC:95.0000\n",
      "train Loss:0.1800 Acc:95.000000%\n",
      "Validing...\n",
      "valid Loss:0.4867 Acc:79.000000%\n",
      "Epoch3/4\n",
      "----------\n",
      "Training...\n",
      "Batch10,TrainLoss:0.1049,Train ACC:99.0000\n",
      "Batch20,TrainLoss:0.1035,Train ACC:98.0000\n",
      "Batch30,TrainLoss:0.0981,Train ACC:98.0000\n",
      "Batch40,TrainLoss:0.0980,Train ACC:98.0000\n",
      "Batch50,TrainLoss:0.1004,Train ACC:98.0000\n",
      "Batch60,TrainLoss:0.1013,Train ACC:98.0000\n",
      "Batch70,TrainLoss:0.0971,Train ACC:98.0000\n",
      "Batch80,TrainLoss:0.0955,Train ACC:98.0000\n",
      "Batch90,TrainLoss:0.0968,Train ACC:98.0000\n",
      "Batch100,TrainLoss:0.0995,Train ACC:98.0000\n",
      "Batch110,TrainLoss:0.1009,Train ACC:98.0000\n",
      "train Loss:0.1012 Acc:98.000000%\n",
      "Validing...\n",
      "valid Loss:0.5020 Acc:78.000000%\n",
      "Epoch4/4\n",
      "----------\n",
      "Training...\n",
      "Batch10,TrainLoss:0.0648,Train ACC:100.0000\n",
      "Batch20,TrainLoss:0.0601,Train ACC:99.0000\n",
      "Batch30,TrainLoss:0.0548,Train ACC:99.0000\n",
      "Batch40,TrainLoss:0.0526,Train ACC:99.0000\n",
      "Batch50,TrainLoss:0.0548,Train ACC:99.0000\n",
      "Batch60,TrainLoss:0.0550,Train ACC:99.0000\n",
      "Batch70,TrainLoss:0.0546,Train ACC:99.0000\n",
      "Batch80,TrainLoss:0.0539,Train ACC:99.0000\n",
      "Batch90,TrainLoss:0.0524,Train ACC:99.0000\n",
      "Batch100,TrainLoss:0.0526,Train ACC:99.0000\n",
      "Batch110,TrainLoss:0.0520,Train ACC:99.0000\n",
      "train Loss:0.0528 Acc:99.000000%\n",
      "Validing...\n",
      "valid Loss:0.5386 Acc:77.000000%\n",
      "10617.052728176117\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    print(\"Epoch{}/{}\".format(epoch,epoch_n-1))\n",
    "    print(\"-\"*10)\n",
    "    for phase in {\"train\",\"valid\"}:\n",
    "        if phase == \"train\":\n",
    "            print(\"Training...\")\n",
    "            model.train(True)\n",
    "        else:\n",
    "            print(\"Validing...\")\n",
    "            model.train(False)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for batch, data in enumerate(dataloader[phase], 1):  # enumerate 得到下标和数据\n",
    "            X, y = data\n",
    "            if Use_gpu:\n",
    "                X, y = Variable(X.cuda()), Variable(y.cuda())  # **************************************\n",
    "            else:\n",
    "                X, y = Variable(X), Variable(y)\n",
    "            y_pred = model(X)  # 预测\n",
    "            _, pred = torch.max(y_pred, 1)\n",
    "            optimizer.zero_grad()  # 梯度归零\n",
    "            loss = loss_f(y_pred, y)  # 设置损失\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()  # 反向传播\n",
    "                optimizer.step()  # 更新参数\n",
    "            running_loss += loss.item()\n",
    "            running_corrects += torch.sum(pred == y.data)\n",
    "\n",
    "            if batch % 10 == 0 and phase == \"train\":\n",
    "                print(\"Batch{},TrainLoss:{:.4f},Train ACC:{:.4f}\".format(\n",
    "                    batch, running_loss / batch, 100 * running_corrects / (16 * batch)))\n",
    "        epocn_loss = running_loss * 16 / len(image_datasets[phase])\n",
    "        epoch_acc = 100 * running_corrects / len(image_datasets[phase])\n",
    "        print(\"{} Loss:{:.4f} Acc:{:4f}%\".format(phase, epocn_loss, epoch_acc))\n",
    "time_end = time.time() - time_open\n",
    "print(time_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'F:\\DataSets/VGG16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
